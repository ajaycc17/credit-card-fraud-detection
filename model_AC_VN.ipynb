{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "train_data = pd.read_csv(\"training_data.csv\")\n",
    "train_class = pd.read_csv(\"train_data_classlabels.csv\")\n",
    "test_data = pd.read_csv(\"testing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50920</td>\n",
       "      <td>1.086640</td>\n",
       "      <td>0.148385</td>\n",
       "      <td>0.120522</td>\n",
       "      <td>0.974415</td>\n",
       "      <td>-0.035925</td>\n",
       "      <td>-0.406007</td>\n",
       "      <td>0.270339</td>\n",
       "      <td>-0.139679</td>\n",
       "      <td>-0.411854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.112405</td>\n",
       "      <td>0.221430</td>\n",
       "      <td>-0.226960</td>\n",
       "      <td>0.046246</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>-0.336475</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>76.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34737</td>\n",
       "      <td>1.294054</td>\n",
       "      <td>0.152664</td>\n",
       "      <td>0.195524</td>\n",
       "      <td>0.540694</td>\n",
       "      <td>-0.267245</td>\n",
       "      <td>-0.691144</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.175527</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087916</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>-0.163730</td>\n",
       "      <td>-0.064862</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.504450</td>\n",
       "      <td>-0.033823</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11090</td>\n",
       "      <td>-0.352305</td>\n",
       "      <td>0.614321</td>\n",
       "      <td>2.000903</td>\n",
       "      <td>-0.403523</td>\n",
       "      <td>-0.409279</td>\n",
       "      <td>-0.395518</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.995869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059598</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>0.312846</td>\n",
       "      <td>-0.146312</td>\n",
       "      <td>0.317882</td>\n",
       "      <td>-0.307554</td>\n",
       "      <td>0.975876</td>\n",
       "      <td>-0.047407</td>\n",
       "      <td>0.033127</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23194</td>\n",
       "      <td>-2.049784</td>\n",
       "      <td>1.004759</td>\n",
       "      <td>1.726403</td>\n",
       "      <td>1.600998</td>\n",
       "      <td>-1.121759</td>\n",
       "      <td>0.421037</td>\n",
       "      <td>-0.768145</td>\n",
       "      <td>1.133876</td>\n",
       "      <td>1.207850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155066</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>0.445599</td>\n",
       "      <td>-0.234451</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.325920</td>\n",
       "      <td>-0.050118</td>\n",
       "      <td>0.257527</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>76.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38531</td>\n",
       "      <td>-0.289738</td>\n",
       "      <td>0.880936</td>\n",
       "      <td>1.787349</td>\n",
       "      <td>0.887265</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>-0.845201</td>\n",
       "      <td>1.256896</td>\n",
       "      <td>-0.632290</td>\n",
       "      <td>-0.260688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.062741</td>\n",
       "      <td>0.503452</td>\n",
       "      <td>-0.202127</td>\n",
       "      <td>0.709686</td>\n",
       "      <td>-0.190366</td>\n",
       "      <td>-0.386543</td>\n",
       "      <td>-0.305748</td>\n",
       "      <td>-0.307859</td>\n",
       "      <td>30.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  50920  1.086640  0.148385  0.120522  0.974415 -0.035925 -0.406007   \n",
       "1  34737  1.294054  0.152664  0.195524  0.540694 -0.267245 -0.691144   \n",
       "2  11090 -0.352305  0.614321  2.000903 -0.403523 -0.409279 -0.395518   \n",
       "3  23194 -2.049784  1.004759  1.726403  1.600998 -1.121759  0.421037   \n",
       "4  38531 -0.289738  0.880936  1.787349  0.887265  0.125174 -0.845201   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.270339 -0.139679 -0.411854  ...  0.086793  0.112405  0.221430 -0.226960   \n",
       "1  0.001673 -0.175527  0.179203  ... -0.087916  0.055098  0.213211 -0.163730   \n",
       "2  0.094420  0.066611  0.995869  ... -0.059598  0.055236  0.312846 -0.146312   \n",
       "3 -0.768145  1.133876  1.207850  ...  0.155066  0.085733  0.445599 -0.234451   \n",
       "4  1.256896 -0.632290 -0.260688  ...  0.073293  0.062741  0.503452 -0.202127   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.046246  0.708183 -0.336475  0.002364  0.021463   76.10  \n",
       "1 -0.064862  0.606466  0.504450 -0.033823  0.006327    5.95  \n",
       "2  0.317882 -0.307554  0.975876 -0.047407  0.033127   14.95  \n",
       "3  0.040248  0.325920 -0.050118  0.257527 -0.015911   76.60  \n",
       "4  0.709686 -0.190366 -0.386543 -0.305748 -0.307859   30.54  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57116 entries, 0 to 57115\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    57116 non-null  int64  \n",
      " 1   V1      57116 non-null  float64\n",
      " 2   V2      57116 non-null  float64\n",
      " 3   V3      57116 non-null  float64\n",
      " 4   V4      57116 non-null  float64\n",
      " 5   V5      57116 non-null  float64\n",
      " 6   V6      57116 non-null  float64\n",
      " 7   V7      57116 non-null  float64\n",
      " 8   V8      57116 non-null  float64\n",
      " 9   V9      57116 non-null  float64\n",
      " 10  V10     57116 non-null  float64\n",
      " 11  V11     57116 non-null  float64\n",
      " 12  V12     57116 non-null  float64\n",
      " 13  V13     57116 non-null  float64\n",
      " 14  V14     57116 non-null  float64\n",
      " 15  V15     57116 non-null  float64\n",
      " 16  V16     57116 non-null  float64\n",
      " 17  V17     57116 non-null  float64\n",
      " 18  V18     57116 non-null  float64\n",
      " 19  V19     57116 non-null  float64\n",
      " 20  V20     57116 non-null  float64\n",
      " 21  V21     57116 non-null  float64\n",
      " 22  V22     57116 non-null  float64\n",
      " 23  V23     57116 non-null  float64\n",
      " 24  V24     57116 non-null  float64\n",
      " 25  V25     57116 non-null  float64\n",
      " 26  V26     57116 non-null  float64\n",
      " 27  V27     57116 non-null  float64\n",
      " 28  V28     57116 non-null  float64\n",
      " 29  Amount  57116 non-null  float64\n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 13.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "      <td>57116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34983.116097</td>\n",
       "      <td>-0.247795</td>\n",
       "      <td>-0.022058</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>-0.269839</td>\n",
       "      <td>0.099197</td>\n",
       "      <td>-0.111731</td>\n",
       "      <td>0.053520</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044174</td>\n",
       "      <td>-0.029317</td>\n",
       "      <td>-0.106932</td>\n",
       "      <td>-0.037896</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.134607</td>\n",
       "      <td>0.021532</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>96.941060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14565.105294</td>\n",
       "      <td>1.864050</td>\n",
       "      <td>1.631035</td>\n",
       "      <td>1.410986</td>\n",
       "      <td>1.373157</td>\n",
       "      <td>1.377401</td>\n",
       "      <td>1.301175</td>\n",
       "      <td>1.247802</td>\n",
       "      <td>1.249071</td>\n",
       "      <td>1.157104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756907</td>\n",
       "      <td>0.746801</td>\n",
       "      <td>0.639153</td>\n",
       "      <td>0.626419</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>0.497490</td>\n",
       "      <td>0.379231</td>\n",
       "      <td>0.295386</td>\n",
       "      <td>270.411899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-36.802320</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.172595</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-9.283925</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.806476</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28865.000000</td>\n",
       "      <td>-1.009543</td>\n",
       "      <td>-0.589424</td>\n",
       "      <td>0.192506</td>\n",
       "      <td>-0.723950</td>\n",
       "      <td>-0.887752</td>\n",
       "      <td>-0.640141</td>\n",
       "      <td>-0.601216</td>\n",
       "      <td>-0.143972</td>\n",
       "      <td>-0.675191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169140</td>\n",
       "      <td>-0.226106</td>\n",
       "      <td>-0.525390</td>\n",
       "      <td>-0.177981</td>\n",
       "      <td>-0.324780</td>\n",
       "      <td>-0.129791</td>\n",
       "      <td>-0.329274</td>\n",
       "      <td>-0.063496</td>\n",
       "      <td>-0.006171</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38190.500000</td>\n",
       "      <td>-0.246743</td>\n",
       "      <td>0.074316</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.189497</td>\n",
       "      <td>-0.301686</td>\n",
       "      <td>-0.151700</td>\n",
       "      <td>-0.071382</td>\n",
       "      <td>0.065374</td>\n",
       "      <td>-0.073948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024862</td>\n",
       "      <td>-0.060934</td>\n",
       "      <td>-0.081307</td>\n",
       "      <td>-0.049691</td>\n",
       "      <td>0.062927</td>\n",
       "      <td>0.172505</td>\n",
       "      <td>-0.076244</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>26.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46008.250000</td>\n",
       "      <td>1.153809</td>\n",
       "      <td>0.724232</td>\n",
       "      <td>1.399763</td>\n",
       "      <td>1.052439</td>\n",
       "      <td>0.268297</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.423102</td>\n",
       "      <td>0.345135</td>\n",
       "      <td>0.663857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169582</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>0.307514</td>\n",
       "      <td>0.080841</td>\n",
       "      <td>0.403506</td>\n",
       "      <td>0.421531</td>\n",
       "      <td>0.300119</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.075379</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54280.000000</td>\n",
       "      <td>1.634039</td>\n",
       "      <td>18.902453</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>17.297845</td>\n",
       "      <td>4.014444</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>5.678671</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  57116.000000  57116.000000  57116.000000  57116.000000  57116.000000   \n",
       "mean   34983.116097     -0.247795     -0.022058      0.679284      0.169507   \n",
       "std    14565.105294      1.864050      1.631035      1.410986      1.373157   \n",
       "min        0.000000    -36.802320    -63.344698    -33.680984     -5.172595   \n",
       "25%    28865.000000     -1.009543     -0.589424      0.192506     -0.723950   \n",
       "50%    38190.500000     -0.246743      0.074316      0.768041      0.189497   \n",
       "75%    46008.250000      1.153809      0.724232      1.399763      1.052439   \n",
       "max    54280.000000      1.634039     18.902453      4.101716     16.715537   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  57116.000000  57116.000000  57116.000000  57116.000000  57116.000000   \n",
       "mean      -0.269839      0.099197     -0.111731      0.053520      0.013406   \n",
       "std        1.377401      1.301175      1.247802      1.249071      1.157104   \n",
       "min      -42.147898    -23.496714    -31.764946    -73.216718     -9.283925   \n",
       "25%       -0.887752     -0.640141     -0.601216     -0.143972     -0.675191   \n",
       "50%       -0.301686     -0.151700     -0.071382      0.065374     -0.073948   \n",
       "75%        0.268297      0.491501      0.423102      0.345135      0.663857   \n",
       "max       34.099309     22.529298     36.677268     20.007208     10.392889   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  57116.000000  57116.000000  57116.000000  57116.000000   \n",
       "mean   ...      0.044174     -0.029317     -0.106932     -0.037896   \n",
       "std    ...      0.756907      0.746801      0.639153      0.626419   \n",
       "min    ...    -15.806476    -34.830382    -10.933144    -26.751119   \n",
       "25%    ...     -0.169140     -0.226106     -0.525390     -0.177981   \n",
       "50%    ...     -0.024862     -0.060934     -0.081307     -0.049691   \n",
       "75%    ...      0.169582      0.115353      0.307514      0.080841   \n",
       "max    ...     39.420904     22.614889     10.503090     17.297845   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  57116.000000  57116.000000  57116.000000  57116.000000  57116.000000   \n",
       "mean       0.006357      0.134607      0.021532      0.002800      0.001178   \n",
       "std        0.597128      0.439791      0.497490      0.379231      0.295386   \n",
       "min       -2.836627     -7.495741     -2.534330     -7.976100     -9.617915   \n",
       "25%       -0.324780     -0.129791     -0.329274     -0.063496     -0.006171   \n",
       "50%        0.062927      0.172505     -0.076244      0.009027      0.022540   \n",
       "75%        0.403506      0.421531      0.300119      0.082192      0.075379   \n",
       "max        4.014444      5.525093      3.517346     11.135740      5.678671   \n",
       "\n",
       "             Amount  \n",
       "count  57116.000000  \n",
       "mean      96.941060  \n",
       "std      270.411899  \n",
       "min        0.000000  \n",
       "25%        7.600000  \n",
       "50%       26.265000  \n",
       "75%       88.000000  \n",
       "max    19656.530000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no null values\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no null values in the dataset\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    56974\n",
      "1.0      142\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# highly imbalanced dataset\n",
    "print(train_class['Class'].value_counts())\n",
    "sns.countplot(train_class[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.086640</td>\n",
       "      <td>0.148385</td>\n",
       "      <td>0.120522</td>\n",
       "      <td>0.974415</td>\n",
       "      <td>-0.035925</td>\n",
       "      <td>-0.406007</td>\n",
       "      <td>0.270339</td>\n",
       "      <td>-0.139679</td>\n",
       "      <td>-0.411854</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112405</td>\n",
       "      <td>0.221430</td>\n",
       "      <td>-0.226960</td>\n",
       "      <td>0.046246</td>\n",
       "      <td>0.708183</td>\n",
       "      <td>-0.336475</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.619838</td>\n",
       "      <td>0.742537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.294054</td>\n",
       "      <td>0.152664</td>\n",
       "      <td>0.195524</td>\n",
       "      <td>0.540694</td>\n",
       "      <td>-0.267245</td>\n",
       "      <td>-0.691144</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.175527</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>-0.032250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>-0.163730</td>\n",
       "      <td>-0.064862</td>\n",
       "      <td>0.606466</td>\n",
       "      <td>0.504450</td>\n",
       "      <td>-0.033823</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>-0.252674</td>\n",
       "      <td>-0.201450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.352305</td>\n",
       "      <td>0.614321</td>\n",
       "      <td>2.000903</td>\n",
       "      <td>-0.403523</td>\n",
       "      <td>-0.409279</td>\n",
       "      <td>-0.395518</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.995869</td>\n",
       "      <td>-0.783621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>0.312846</td>\n",
       "      <td>-0.146312</td>\n",
       "      <td>0.317882</td>\n",
       "      <td>-0.307554</td>\n",
       "      <td>0.975876</td>\n",
       "      <td>-0.047407</td>\n",
       "      <td>0.033127</td>\n",
       "      <td>-0.140734</td>\n",
       "      <td>-1.580826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.049784</td>\n",
       "      <td>1.004759</td>\n",
       "      <td>1.726403</td>\n",
       "      <td>1.600998</td>\n",
       "      <td>-1.121759</td>\n",
       "      <td>0.421037</td>\n",
       "      <td>-0.768145</td>\n",
       "      <td>1.133876</td>\n",
       "      <td>1.207850</td>\n",
       "      <td>-0.764514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>0.445599</td>\n",
       "      <td>-0.234451</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.325920</td>\n",
       "      <td>-0.050118</td>\n",
       "      <td>0.257527</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>0.626057</td>\n",
       "      <td>-0.874776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.289738</td>\n",
       "      <td>0.880936</td>\n",
       "      <td>1.787349</td>\n",
       "      <td>0.887265</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>-0.845201</td>\n",
       "      <td>1.256896</td>\n",
       "      <td>-0.632290</td>\n",
       "      <td>-0.260688</td>\n",
       "      <td>0.284519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062741</td>\n",
       "      <td>0.503452</td>\n",
       "      <td>-0.202127</td>\n",
       "      <td>0.709686</td>\n",
       "      <td>-0.190366</td>\n",
       "      <td>-0.386543</td>\n",
       "      <td>-0.305748</td>\n",
       "      <td>-0.307859</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>0.019862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.086640  0.148385  0.120522  0.974415 -0.035925 -0.406007  0.270339   \n",
       "1  1.294054  0.152664  0.195524  0.540694 -0.267245 -0.691144  0.001673   \n",
       "2 -0.352305  0.614321  2.000903 -0.403523 -0.409279 -0.395518  0.094420   \n",
       "3 -2.049784  1.004759  1.726403  1.600998 -1.121759  0.421037 -0.768145   \n",
       "4 -0.289738  0.880936  1.787349  0.887265  0.125174 -0.845201  1.256896   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.139679 -0.411854  0.122070  ...  0.112405  0.221430 -0.226960  0.046246   \n",
       "1 -0.175527  0.179203 -0.032250  ...  0.055098  0.213211 -0.163730 -0.064862   \n",
       "2  0.066611  0.995869 -0.783621  ...  0.055236  0.312846 -0.146312  0.317882   \n",
       "3  1.133876  1.207850 -0.764514  ...  0.085733  0.445599 -0.234451  0.040248   \n",
       "4 -0.632290 -0.260688  0.284519  ...  0.062741  0.503452 -0.202127  0.709686   \n",
       "\n",
       "        V25       V26       V27       V28  scaled_amount  scaled_time  \n",
       "0  0.708183 -0.336475  0.002364  0.021463       0.619838     0.742537  \n",
       "1  0.606466  0.504450 -0.033823  0.006327      -0.252674    -0.201450  \n",
       "2 -0.307554  0.975876 -0.047407  0.033127      -0.140734    -1.580826  \n",
       "3  0.325920 -0.050118  0.257527 -0.015911       0.626057    -0.874776  \n",
       "4 -0.190366 -0.386543 -0.305748 -0.307859       0.053172     0.019862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data: RobustScaler is less prone to outliers.\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "train_data['scaled_amount'] = rob_scaler.fit_transform(\n",
    "    train_data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "train_data['scaled_time'] = rob_scaler.fit_transform(\n",
    "    train_data['Time'].values.reshape(-1, 1))\n",
    "    \n",
    "train_data.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "# visualize the data\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legit: 142 & Fraud : 56974\n"
     ]
    }
   ],
   "source": [
    "# merge the train data and labels\n",
    "traind = train_data.copy()\n",
    "traind['Class'] = train_class['Class']\n",
    "\n",
    "# this is an unbalanced dataset\n",
    "legit = traind[traind[\"Class\"] == 0]\n",
    "fraud = traind[traind[\"Class\"] == 1]\n",
    "\n",
    "# print the legit and fraud transactions\n",
    "print(\n",
    "    f'Legit: {fraud.Class.value_counts()[1]} & Fraud : {legit.Class.value_counts()[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with the ratio of both the classes same\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in split.split(traind, traind['Class']):\n",
    "    X_train = traind.loc[train_index]\n",
    "    X_test = traind.loc[test_index]\n",
    "\n",
    "# labels\n",
    "Y_train = pd.DataFrame(X_train['Class'])\n",
    "Y_test = pd.DataFrame(X_test['Class'])\n",
    "\n",
    "# drop the class labels from the training and test data\n",
    "X_train.drop(columns=\"Class\", inplace=True)\n",
    "X_test.drop(columns=\"Class\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    39882\n",
      "1.0       99\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    17092\n",
       "1.0       43\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_train['Class'].value_counts())\n",
    "Y_test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering or Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14              0.012491\n",
       "V17              0.012375\n",
       "V12              0.012040\n",
       "V11              0.011871\n",
       "V10              0.011587\n",
       "V4               0.010008\n",
       "V16              0.009806\n",
       "V3               0.009267\n",
       "V9               0.008544\n",
       "V18              0.008458\n",
       "V7               0.007947\n",
       "V2               0.006906\n",
       "V6               0.005889\n",
       "V27              0.005606\n",
       "V21              0.005508\n",
       "V5               0.005429\n",
       "V1               0.004988\n",
       "V8               0.004642\n",
       "V28              0.004378\n",
       "scaled_amount    0.003185\n",
       "V20              0.002812\n",
       "V19              0.002511\n",
       "scaled_time      0.002371\n",
       "V25              0.001892\n",
       "V23              0.001511\n",
       "V26              0.001239\n",
       "V24              0.000958\n",
       "V15              0.000657\n",
       "V22              0.000291\n",
       "V13              0.000178\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "mutual_info = mutual_info_classif(X_train, Y_train)\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the feature importance\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select top 15 features\n",
    "selector = SelectKBest(mutual_info_classif, k=5)\n",
    "selector.fit(X_train, Y_train)\n",
    "\n",
    "# Get columns to keep and create new dataframe - \"new_train\"\n",
    "cols = selector.get_support(indices=True)\n",
    "\n",
    "# new dataframes\n",
    "new_train = X_train.iloc[:,cols]\n",
    "new_test = X_test.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(new_train, Y_train)\n",
    "test_pred = dt.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On training data, DT has a AUCROC Score of: 100.0\n",
      "On test data, DT has a AUCROC Score of: 90.67134631188806\n"
     ]
    }
   ],
   "source": [
    "# AUC ROC scores on the training and test dataset\n",
    "AUC_ROC_Score = roc_auc_score(Y_train, dt.predict_proba(new_train)[:, 1])\n",
    "print(\"On training data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)\n",
    "\n",
    "AUC_ROC_Score = roc_auc_score(Y_test, dt.predict_proba(new_test)[:, 1])\n",
    "print(\"On test data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning to overcome Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting can be seen clearly\n",
    "params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1, 20),\n",
    "    'max_features': ('auto', 'sqrt', 'log2'),\n",
    "    # 'ccp_alpha': (for later)\n",
    "}\n",
    "grid = GridSearchCV(dt, param_grid=params, cv=10,\n",
    "                    scoring='roc_auc')  # 10 fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(new_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dt = grid.best_estimator_\n",
    "new_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating pruning alpha values\n",
    "path = new_dt.cost_complexity_pruning_path(new_train, Y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(new_train, Y_train)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [roc_auc_score(\n",
    "    Y_train, clf.predict_proba(new_train)[:, 1]) for clf in clfs]\n",
    "test_scores = [roc_auc_score(Y_test, clf.predict_proba(new_test)[\n",
    "                             :, 1]) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"AUCROC\")\n",
    "ax.set_title(\"AUCROC vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best ccp_alpha value with lowest bias and variance\n",
    "min = train_scores[0]-test_scores[0]\n",
    "count = 0\n",
    "for (i, j) in zip(train_scores, test_scores):\n",
    "    if (i-j) != 0 and (i-j) < min:\n",
    "        min = i-j\n",
    "        tr = i\n",
    "        tt = j\n",
    "        index = count\n",
    "    count = count + 1\n",
    "\n",
    "print(\n",
    "    f\"Difference in AUCROC score: {min*100}\\nScore on training dataset: {tr*100}\\nScore on test dataset: {tt*100}\\nIndex of ccp_alpha: {index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alphas[index])\n",
    "clf.fit(new_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = clf.predict(new_test)\n",
    "Y_pred_train = clf.predict(new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC ROC scores on the training and test dataset\n",
    "AUC_ROC_Score = roc_auc_score(Y_train, clf.predict_proba(new_train)[:, 1])\n",
    "print(\"On training data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)\n",
    "\n",
    "AUC_ROC_Score = roc_auc_score(Y_test, clf.predict_proba(new_test)[:, 1])\n",
    "print(\"On test data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Confusion Matrix \\n')\n",
    "print(confusion_matrix(Y_predicted, Y_test))\n",
    "\n",
    "ac = accuracy_score(Y_test, Y_predicted)\n",
    "print('\\n Macro Averaged Accuracy :'+str(ac))\n",
    "\n",
    "pr = precision_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged Precision :'+str(pr))\n",
    "\n",
    "re = recall_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged Recall :'+str(re))\n",
    "\n",
    "fm = f1_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged F1-Score :'+str(fm))\n",
    "\n",
    "fm = f1_score(Y_train, Y_pred_train, average='macro')\n",
    "print('\\n Macro Averaged F1-Score on training :'+str(fm))\n",
    "\n",
    "fm = f1_score(Y_test, Y_predicted, average='micro')\n",
    "print('\\n Micro Averaged F1-Score:'+str(fm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(Y_test, Y_predicted)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "tree.plot_tree(clf, filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# training the random forest model on original features\n",
    "rf = rf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC ROC scores on the training and test dataset\n",
    "AUC_ROC_Score = roc_auc_score(Y_train, rf.predict_proba(X_train)[:, 1])\n",
    "print(\"On training data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)\n",
    "\n",
    "AUC_ROC_Score = roc_auc_score(Y_test, rf.predict_proba(X_test)[:, 1])\n",
    "print(\"On test data, DT has a AUCROC Score of:\", AUC_ROC_Score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = rf.predict(X_test)\n",
    "Y_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Confusion Matrix \\n')\n",
    "print(confusion_matrix(Y_predicted, Y_test))\n",
    "\n",
    "ac = accuracy_score(Y_test, Y_predicted)\n",
    "print('\\n Macro Averaged Accuracy :'+str(ac))\n",
    "\n",
    "pr = precision_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged Precision :'+str(pr))\n",
    "\n",
    "re = recall_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged Recall :'+str(re))\n",
    "\n",
    "fm = f1_score(Y_test, Y_predicted, average='macro')\n",
    "print('\\n Macro Averaged F1-Score :'+str(fm))\n",
    "\n",
    "fm = f1_score(Y_test, Y_predicted, average='micro')\n",
    "print('\\n Micro Averaged F1-Score:'+str(fm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(Y_test, Y_predicted)\n",
    "\n",
    "#create precision recall curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='purple')\n",
    "\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "\n",
    "#display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        model.fit(X_train,Y_train)\n",
    "        #cv_score = cross_val_score(model,X_train,Y_train,cv=5)\n",
    "        #print(key, \"has a training Cross Val score of\", round(cv_score.mean(), 2) * 100, \"% accuracy score\")\n",
    "        AUC_ROC_Score= roc_auc_score(Y_train, model.predict_proba(X_train)[:, 1])\n",
    "        #AUC_PRC_Score=precision_recall_curve(Y_train, model1.predict_proba(X_train)[:, 1])\n",
    "        print(key, \"has a AUCROC Score of\", AUC_ROC_Score)\n",
    "        #print(key, \"has a AUCPRC Score of\", AUC_PRC_Score * 100)\n",
    "        \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1.fit(X_train, Y_train).predict(X_train)\n",
    "train_acc = accuracy_score(Y_train_pred, Y_train)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model1.predict(X_test)\n",
    "test_acc = accuracy_score(Y_test_pred, Y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data: RobustScaler is less prone to outliers.\n",
    "test_data['scaled_amount'] = rob_scaler.fit_transform(\n",
    "    test_data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "test_data['scaled_time'] = rob_scaler.fit_transform(\n",
    "    test_data['Time'].values.reshape(-1, 1))\n",
    "    \n",
    "test_data.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "# visualize the data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data has null values\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using imputer to put median of the feature in place of null values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(test_data)\n",
    "X = imputer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = pd.DataFrame(X, columns=test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the classes of the test data\n",
    "pred_test_data = rf.predict(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred_test_data, columns = ['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Class'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a15a8350f781044c0a330f52c29cbc032f750b45230b27500680e010145e1d1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
